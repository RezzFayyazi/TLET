import torch

from ExploitTypes import Types
from fastai import *
from fastai.text import *
from fastai.vision.all import *


out_path = './'
if not torch.cuda.is_available():
	print("ERROR: CUDA not available.")
else :
	torch.cuda.set_device(0)
	torch.multiprocessing.freeze_support()

	
DEFAULT_CLASSIFIER_LOCATION = 'export.pkl'
CUSTOM_CLASSIFIER_LOCATION = ''

class ExploitTypesPredictor :

	'''
	Loads in the classifier model using the supplied models or a custom model.
	'''
	def __init__(self, pred_model='DEFAULT', model_loc=DEFAULT_CLASSIFIER_LOCATION) :
	
		if pred_model == 'DEFAULT' :
			self.classifier_model = load_learner(DEFAULT_CLASSIFIER_LOCATION)
		elif pred_model == 'CUSTOM' :
			self.classifier_model = load_learner(model_loc)
		else :
			raise Exception('Unsupported prediction model type.  Consider CUSTOM.')

		return
	
	'''
	Predicts the top-1 given the input text.  Outputs Exploit types.  
	'''
	def predict(self, text:str) -> Types:
		pred = self.classifier_model.predict(text)
		return pred


